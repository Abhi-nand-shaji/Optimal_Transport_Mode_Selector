{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhi-nand-shaji/Optimal_Transport_Mode_Selector/blob/main/SER_ML_(Final).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oOAHKA4lJId"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.compose import ColumnTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AINPb8JJOh9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecfaf4b8-ce56-4dfd-9063-e98cc9ee416b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 1: Load & Clean Data ---\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/ML data/DataforML.csv\", skiprows=1)\n",
        "# --- Rename Columns ---\n",
        "df.columns = [\n",
        "    \"Perishable\", \"Commodity\", \"Category\", \"Source\", \"Destination\", \"Density\", \"Demand\",\n",
        "    \"Distance_Rail\", \"Distance_Road\", \"Distance_Air\", \"Distance_Hyperloop\",\n",
        "    \"Time_Rail\", \"Time_Road\", \"Time_Air\", \"Time_Hyperloop\",\n",
        "    \"Cost_Rail\", \"Cost_Road\", \"Cost_Air\", \"Cost_Hyperloop\",\n",
        "    \"Carbon_Rail\", \"Carbon_Road\", \"Carbon_Air\", \"Carbon_Hyperloop\",\n",
        "    \"Unused1\", \"Unused2\"\n",
        "]\n",
        "df = df.drop(columns=[\"Unused1\", \"Unused2\"])"
      ],
      "metadata": {
        "id": "mfxFhgAXlQCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert necessary columns to numeric\n",
        "cols_to_convert = [\n",
        "    \"Distance_Rail\", \"Distance_Road\", \"Distance_Air\", \"Distance_Hyperloop\",\n",
        "    \"Time_Rail\", \"Time_Road\", \"Time_Air\", \"Time_Hyperloop\",\n",
        "    \"Cost_Rail\", \"Cost_Road\", \"Cost_Air\", \"Cost_Hyperloop\",\n",
        "    \"Carbon_Rail\", \"Carbon_Road\", \"Carbon_Air\", \"Carbon_Hyperloop\",\n",
        "    \"Demand\", \"Density\", \"Perishable\"\n",
        "]\n",
        "\n",
        "for col in cols_to_convert:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Drop rows with any NaNs\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "HWXUDsYoliR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize Cost, Time, Carbon\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler_minmax = MinMaxScaler()\n",
        "for metric in [\"Cost\", \"Time\", \"Carbon\"]:\n",
        "    for mode in [\"Rail\", \"Road\", \"Air\", \"Hyperloop\"]:\n",
        "        df[f\"{metric}_{mode}\"] = scaler_minmax.fit_transform(df[[f\"{metric}_{mode}\"]])"
      ],
      "metadata": {
        "id": "tLxQhC78lk-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP3pFPz2spk-",
        "outputId": "1450bb7b-09d6-4c07-b0c8-94a990d743e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Perishable              Commodity        Category   Source Destination  \\\n",
            "0         1.0                   Milk            FMCG  Chennai   Bangalore   \n",
            "1         1.0        Packaged Snacks            FMCG  Chennai   Bangalore   \n",
            "2         1.0                   Meat            FMCG  Chennai   Bangalore   \n",
            "3         1.0               Seafoods            FMCG  Chennai   Bangalore   \n",
            "4         1.0                Pickles            FMCG  Chennai   Bangalore   \n",
            "5         1.0           Leafy Greens  fruits/veggies  Chennai   Bangalore   \n",
            "6         1.0              Mushrooms  fruits/veggies  Chennai   Bangalore   \n",
            "7         1.0             Cut Fruits  fruits/veggies  Chennai   Bangalore   \n",
            "8         1.0               Vaccines          pharma  Chennai   Bangalore   \n",
            "9         1.0  Rapid Diagnostic Kits          pharma  Chennai   Bangalore   \n",
            "\n",
            "   Density  Demand  Distance_Rail  Distance_Road  Distance_Air  ...  Time_Air  \\\n",
            "0   1030.0     9.0          347.0          326.0         284.0  ...  0.103448   \n",
            "1    250.0     7.0          347.0          326.0         284.0  ...  0.103448   \n",
            "2   1060.0     8.0          347.0          326.0         284.0  ...  0.103448   \n",
            "3   1080.0     8.0          347.0          326.0         284.0  ...  0.103448   \n",
            "4   1100.0     6.0          347.0          326.0         284.0  ...  0.103448   \n",
            "5    150.0     9.0          347.0          326.0         284.0  ...  0.103448   \n",
            "6    160.0     8.0          347.0          326.0         284.0  ...  0.103448   \n",
            "7    600.0     9.0          347.0          326.0         284.0  ...  0.103448   \n",
            "8   1000.0    10.0          347.0          326.0         284.0  ...  0.103448   \n",
            "9    450.0    10.0          347.0          326.0         284.0  ...  0.103448   \n",
            "\n",
            "   Time_Hyperloop  Cost_Rail  Cost_Road  Cost_Air  Cost_Hyperloop  \\\n",
            "0        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "1        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "2        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "3        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "4        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "5        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "6        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "7        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "8        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "9        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "\n",
            "   Carbon_Rail  Carbon_Road  Carbon_Air  Carbon_Hyperloop  \n",
            "0     0.068345     0.087941         0.1          0.057312  \n",
            "1     0.068345     0.087941         0.1          0.057312  \n",
            "2     0.068345     0.087941         0.1          0.057312  \n",
            "3     0.068345     0.087941         0.1          0.057312  \n",
            "4     0.068345     0.087941         0.1          0.057312  \n",
            "5     0.068345     0.087941         0.1          0.057312  \n",
            "6     0.068345     0.087941         0.1          0.057312  \n",
            "7     0.068345     0.087941         0.1          0.057312  \n",
            "8     0.068345     0.087941         0.1          0.057312  \n",
            "9     0.068345     0.087941         0.1          0.057312  \n",
            "\n",
            "[10 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute weighted scores for each mode\n",
        "def get_adjusted_weights(demand_0_to_10, perishable):\n",
        "    base_cost = 0.452\n",
        "    base_carbon = 0.267\n",
        "    base_time = 0.281\n",
        "    demand = min(max(demand_0_to_10 / 10.0, 0), 1)\n",
        "    perishability_factor = 0.1 if perishable else 0.0\n",
        "    demand_factor = demand * 0.2\n",
        "    w_time = base_time + perishability_factor + demand_factor\n",
        "    w_carbon = base_carbon + 0.5 * perishability_factor\n",
        "    w_cost = 1.0 - w_time - w_carbon\n",
        "    return w_cost, w_carbon, w_time\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    w_cost, w_carbon, w_time = get_adjusted_weights(row[\"Demand\"], row[\"Perishable\"])\n",
        "    for mode in [\"Rail\", \"Road\", \"Air\", \"Hyperloop\"]:\n",
        "        df.at[idx, f\"Score_{mode}\"] = (\n",
        "            w_cost * row[f\"Cost_{mode}\"] +\n",
        "            w_carbon * row[f\"Carbon_{mode}\"] +\n",
        "            w_time * row[f\"Time_{mode}\"]\n",
        "        )"
      ],
      "metadata": {
        "id": "032fE7A8lnqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define best mode\n",
        "df[\"Best_Mode\"] = df[[\"Score_Rail\", \"Score_Road\", \"Score_Air\", \"Score_Hyperloop\"]].idxmin(axis=1)\n",
        "df[\"Best_Mode\"] = df[\"Best_Mode\"].map({\n",
        "    \"Score_Rail\": \"rail\",\n",
        "    \"Score_Road\": \"road\",\n",
        "    \"Score_Air\": \"air\",\n",
        "    \"Score_Hyperloop\": \"hyperloop\"\n",
        "})"
      ],
      "metadata": {
        "id": "Fd7dbjs-5_DC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection\n",
        "feature_cols = [\n",
        "    \"Cost_Rail\", \"Cost_Road\", \"Cost_Air\", \"Cost_Hyperloop\",\n",
        "    \"Time_Rail\", \"Time_Road\", \"Time_Air\", \"Time_Hyperloop\",\n",
        "    \"Carbon_Rail\", \"Carbon_Road\", \"Carbon_Air\", \"Carbon_Hyperloop\",\n",
        "    \"Demand\", \"Density\", \"Perishable\"\n",
        "]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[\"Best_Mode\"]"
      ],
      "metadata": {
        "id": "-RuvBFc26G9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all features are numeric\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "X.dropna(inplace=True)\n",
        "y = y.loc[X.index]\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "PWEhwsZMsHui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final check before training\n",
        "print(\"Checking for NaNs in X before scaling...\")\n",
        "print(X.isnull().sum())\n",
        "\n",
        "# Drop rows with any remaining NaNs\n",
        "X = X.dropna()\n",
        "y = y[X.index]  # Ensure y aligns with cleaned X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de4l8ojQm9Tk",
        "outputId": "91ef6542-f03e-4f83-e406-b100962f964c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for NaNs in X before scaling...\n",
            "Cost_Rail           0\n",
            "Cost_Road           0\n",
            "Cost_Air            0\n",
            "Cost_Hyperloop      0\n",
            "Time_Rail           0\n",
            "Time_Road           0\n",
            "Time_Air            0\n",
            "Time_Hyperloop      0\n",
            "Carbon_Rail         0\n",
            "Carbon_Road         0\n",
            "Carbon_Air          0\n",
            "Carbon_Hyperloop    0\n",
            "Demand              0\n",
            "Density             0\n",
            "Perishable          0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Final row count: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGx-lbMRswO6",
        "outputId": "e3a2f69c-10ba-4a40-b641-569d9f92b079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final row count: 2496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and train model\n",
        "mlffnn = MLPClassifier(\n",
        "    hidden_layer_sizes=(400, 300),\n",
        "    activation='relu',\n",
        "    solver='adam',\n",
        "    alpha=0.0005,\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "mlffnn.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = mlffnn.predict(X_test)\n",
        "print(\"\\nðŸ“Š MLFFNN Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvwEUydfsLIM",
        "outputId": "30f99b79-1465-42b6-dc36-ee8361aa2a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“Š MLFFNN Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         air       0.80      1.00      0.89         4\n",
            "   hyperloop       1.00      0.98      0.99       555\n",
            "        rail       0.96      0.99      0.98       182\n",
            "        road       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.99       749\n",
            "   macro avg       0.94      0.99      0.96       749\n",
            "weighted avg       0.99      0.99      0.99       749\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Inverse transform to get original feature values\n",
        "X_original = scaler.inverse_transform(X_test)\n",
        "original_features_df = pd.DataFrame(X_original, columns=feature_cols)\n",
        "\n",
        "# Get source and destination columns corresponding to the test set\n",
        "source_dest_df = df[[\"Source\", \"Destination\"]].loc[X.index].reset_index(drop=True)\n",
        "\n",
        "results_df = pd.DataFrame(y_pred)\n",
        "\n",
        "# Combine all parts\n",
        "final_df = pd.concat([\n",
        "    original_features_df.reset_index(drop=True),\n",
        "    source_dest_df,\n",
        "    results_df\n",
        "], axis=1)\n",
        "\n",
        "# Save to CSV\n",
        "final_df.to_csv(\"ml_predictions_with_originals.csv\", index=False)\n",
        "\n",
        "print(\"\\nâœ… ML predictions with original features saved to 'ml_predictions_with_originals.csv'\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eD5TGbrcBUpz",
        "outputId": "c1e52502-179e-4b46-d5ff-7ae535e71547"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… ML predictions with original features saved to 'ml_predictions_with_originals.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cost_scaler = MinMaxScaler().fit(df[[\"Cost_Rail\", \"Cost_Road\", \"Cost_Air\", \"Cost_Hyperloop\"]])\n",
        "time_scaler = MinMaxScaler().fit(df[[\"Time_Rail\", \"Time_Road\", \"Time_Air\", \"Time_Hyperloop\"]])\n",
        "carbon_scaler = MinMaxScaler().fit(df[[\"Carbon_Rail\", \"Carbon_Road\", \"Carbon_Air\", \"Carbon_Hyperloop\"]])\n"
      ],
      "metadata": {
        "id": "L6fNwmXxYdvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(cost_scaler, \"cost_scaler.pkl\")\n",
        "joblib.dump(time_scaler, \"time_scaler.pkl\")\n",
        "joblib.dump(carbon_scaler, \"carbon_scaler.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMmob9-EYa6j",
        "outputId": "78e9e113-a4e6-40f0-d5cd-8f158c374cf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['carbon_scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize Cost, Time, Carbon\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# ðŸ‘‡ Define these outside so we can reuse them later\n",
        "cost_scaler.pkl = MinMaxScaler()\n",
        "time_scaler.pkl = MinMaxScaler()\n",
        "carbon_scaler.pkl = MinMaxScaler()\n",
        "\n",
        "for metric, scaler in zip([\"Cost\", \"Time\", \"Carbon\"], [cost_scaler, time_scaler, carbon_scaler]):\n",
        "    cols = [f\"{metric}_{mode}\" for mode in [\"Rail\", \"Road\", \"Air\", \"Hyperloop\"]]\n",
        "    df[cols] = scaler.fit_transform(df[cols])\n"
      ],
      "metadata": {
        "id": "D4gsn7YjXKfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "\n",
        "# ---- Step 1: Estimate raw cost, time, and carbon metrics ----\n",
        "def estimate_metrics_from_distance(distance_km):\n",
        "    return {\n",
        "        \"cost\": {\n",
        "            \"rail\": 0.00136 * distance_km,\n",
        "            \"road\": 0.0028 * distance_km,\n",
        "            \"air\": 0.025 * distance_km,\n",
        "            \"hyperloop\": 0.00415242 * distance_km,\n",
        "        },\n",
        "        \"time\": {\n",
        "            \"rail\": (distance_km / 60),\n",
        "            \"road\": (distance_km / 50),\n",
        "            \"air\": (distance_km / 850),\n",
        "            \"hyperloop\": (distance_km / 765)\n",
        "        },\n",
        "        \"carbon\": {\n",
        "            \"rail\": 0.00996 * distance_km,\n",
        "            \"road\": 0.062 * distance_km,\n",
        "            \"air\": 0.6 * distance_km,\n",
        "            \"hyperloop\": 0.006 * distance_km\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "Lrn850-MApU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Step 2: Normalize metrics using fitted scalers ----\n",
        "def normalize_metrics(metrics, cost_scaler, time_scaler, carbon_scaler):\n",
        "    cost_df = pd.DataFrame([{\n",
        "        \"Cost_Rail\": metrics[\"cost\"][\"rail\"],\n",
        "        \"Cost_Road\": metrics[\"cost\"][\"road\"],\n",
        "        \"Cost_Air\": metrics[\"cost\"][\"air\"],\n",
        "        \"Cost_Hyperloop\": metrics[\"cost\"][\"hyperloop\"]\n",
        "    }])\n",
        "    time_df = pd.DataFrame([{\n",
        "        \"Time_Rail\": metrics[\"time\"][\"rail\"],\n",
        "        \"Time_Road\": metrics[\"time\"][\"road\"],\n",
        "        \"Time_Air\": metrics[\"time\"][\"air\"],\n",
        "        \"Time_Hyperloop\": metrics[\"time\"][\"hyperloop\"]\n",
        "    }])\n",
        "    carbon_df = pd.DataFrame([{\n",
        "        \"Carbon_Rail\": metrics[\"carbon\"][\"rail\"],\n",
        "        \"Carbon_Road\": metrics[\"carbon\"][\"road\"],\n",
        "        \"Carbon_Air\": metrics[\"carbon\"][\"air\"],\n",
        "        \"Carbon_Hyperloop\": metrics[\"carbon\"][\"hyperloop\"]\n",
        "    }])\n",
        "\n",
        "    cost_scaled = cost_scaler.transform(cost_df)[0]\n",
        "    time_scaled = time_scaler.transform(time_df)[0]\n",
        "    carbon_scaled = carbon_scaler.transform(carbon_df)[0]\n",
        "\n",
        "    normalized = {\n",
        "        \"cost\": dict(zip([\"rail\", \"road\", \"air\", \"hyperloop\"], cost_scaled)),\n",
        "        \"time\": dict(zip([\"rail\", \"road\", \"air\", \"hyperloop\"], time_scaled)),\n",
        "        \"carbon\": dict(zip([\"rail\", \"road\", \"air\", \"hyperloop\"], carbon_scaled))\n",
        "    }\n",
        "\n",
        "    return normalized"
      ],
      "metadata": {
        "id": "aghE7hHqWQh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Step 3: Calculate weighted scores and return best mode ----\n",
        "def weighted_score_mode_selection(normalized_metrics, demand, perishable):\n",
        "    base_cost = 0.452\n",
        "    base_carbon = 0.267\n",
        "    base_time = 0.281\n",
        "    perishability_factor = 0.1 if perishable else -0.1\n",
        "    demand_factor = min(max(demand / 10.0, 0), 1) * 0.2\n",
        "\n",
        "    w_time = base_time + perishability_factor + demand_factor\n",
        "    w_carbon = base_carbon + 0.1 * perishability_factor\n",
        "    w_cost = 1.0 - w_time - w_carbon\n",
        "\n",
        "    scores = {}\n",
        "    for mode in [\"rail\", \"road\", \"air\", \"hyperloop\"]:\n",
        "        score = (\n",
        "            w_cost * normalized_metrics[\"cost\"][mode] +\n",
        "            w_time * normalized_metrics[\"time\"][mode] +\n",
        "            w_carbon * normalized_metrics[\"carbon\"][mode]\n",
        "        )\n",
        "        scores[mode] = score\n",
        "\n",
        "    best_mode = min(scores, key=scores.get)\n",
        "    return best_mode, scores\n"
      ],
      "metadata": {
        "id": "r5gxr-VjWSI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Step 4: Wrapper to run rule-based prediction ----\n",
        "def rule_based_predict_mode(distance_km, demand, density, perishable, cost_scaler, time_scaler, carbon_scaler):\n",
        "    raw_metrics = estimate_metrics_from_distance(distance_km)\n",
        "    normalized_metrics = normalize_metrics(raw_metrics, cost_scaler, time_scaler, carbon_scaler)\n",
        "    best_mode, score_dict = weighted_score_mode_selection(normalized_metrics, demand, perishable)\n",
        "    return best_mode, score_dict, raw_metrics\n",
        "\n",
        "# ---- Load your previously trained scalers ----\n",
        "cost_scaler = joblib.load(\"cost_scaler.pkl\")\n",
        "time_scaler = joblib.load(\"time_scaler.pkl\")\n",
        "carbon_scaler = joblib.load(\"carbon_scaler.pkl\")\n"
      ],
      "metadata": {
        "id": "zth1hiHuWWyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- Predict best mode for Chennai â†’ Bangalore ----\n",
        "mode, scores, raw = rule_based_predict_mode(\n",
        "    distance_km=1000,\n",
        "    demand=9,\n",
        "    density=600,  # Not used but kept for API consistency\n",
        "    perishable=False,\n",
        "    cost_scaler=cost_scaler,\n",
        "    time_scaler=time_scaler,\n",
        "    carbon_scaler=carbon_scaler\n",
        ")\n",
        "\n",
        "# ---- Display results ----\n",
        "print(\"ðŸšš Rule-Based Best Mode:\", mode)\n",
        "print(\"ðŸ“Š Normalized Scores:\", scores)\n",
        "print(\"ðŸ§¾ Raw Metrics (Unnormalized):\", raw)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8U-5I4FXc4d",
        "outputId": "c95b076f-4ee1-408d-e653-dc4cae9cd688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸšš Rule-Based Best Mode: hyperloop\n",
            "ðŸ“Š Normalized Scores: {'rail': np.float64(9.09590666666667), 'road': np.float64(24.223599999999998), 'air': np.float64(164.17470588235295), 'hyperloop': np.float64(3.6001198648366017)}\n",
            "ðŸ§¾ Raw Metrics (Unnormalized): {'cost': {'rail': 1.36, 'road': 2.8, 'air': 25.0, 'hyperloop': 4.15242}, 'time': {'rail': 16.666666666666668, 'road': 20.0, 'air': 1.1764705882352942, 'hyperloop': 1.3071895424836601}, 'carbon': {'rail': 9.96, 'road': 62.0, 'air': 600.0, 'hyperloop': 6.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM"
      ],
      "metadata": {
        "id": "LwuZ5iCUlv_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Split the data correctly (shuffled and stratified)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Scale only on train\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 3. Train LightGBM or XGBoost cleanly\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "model = LGBMClassifier(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 4. Evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEdowTx7Yf5Y",
        "outputId": "5c5f23a6-9e9b-4e99-b1cc-2a4985000153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000269 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1053\n",
            "[LightGBM] [Info] Number of data points in the train set: 1747, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score -5.268431\n",
            "[LightGBM] [Info] Start training from score -0.300162\n",
            "[LightGBM] [Info] Start training from score -1.411216\n",
            "[LightGBM] [Info] Start training from score -4.575284\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         air       0.80      1.00      0.89         4\n",
            "   hyperloop       1.00      1.00      1.00       555\n",
            "        rail       1.00      0.99      1.00       182\n",
            "        road       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00       749\n",
            "   macro avg       0.95      1.00      0.97       749\n",
            "weighted avg       1.00      1.00      1.00       749\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **XGBoost**"
      ],
      "metadata": {
        "id": "JEJ7uvYFl2-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # Converts ['rail', 'road', ...] â†’ [0, 1, 2, 3]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# ----- Step 2: Scale Features -----\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Save the scaler for future use\n",
        "joblib.dump(scaler, \"xgb_scaler.pkl\")\n",
        "\n",
        "# ----- Step 3: Train XGBoost Model -----\n",
        "xgb_model = XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=len(np.unique(y)),  # number of classes\n",
        "    max_depth=4,\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=100,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(xgb_model, \"xgb_model.pkl\")\n",
        "\n",
        "# ----- Step 4: Evaluate -----\n",
        "y_pred = xgb_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"ðŸ“Š Classification Report for XGBoost:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVBnF2Ukk--l",
        "outputId": "7315ffba-a854-4176-a663-fae1de811981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Classification Report for XGBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         air       0.80      1.00      0.89         4\n",
            "   hyperloop       0.99      1.00      1.00       555\n",
            "        rail       1.00      0.98      0.99       182\n",
            "        road       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.99       749\n",
            "   macro avg       0.95      1.00      0.97       749\n",
            "weighted avg       0.99      0.99      0.99       749\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:00:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RandomForest**"
      ],
      "metadata": {
        "id": "BdIovv4VnNFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "\n",
        "\n",
        "# === Step 3: Label Encode target ===\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # ['rail', 'road', ...] â†’ [0, 1, 2, 3]\n",
        "\n",
        "# === Step 4: Train-test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# === Step 5: Scale features ===\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# === Step 6: Train Random Forest model ===\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42\n",
        ")\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# === Step 7: Evaluate model ===\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(\"ðŸŽ¯ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# === Step 8: Save model and encoders ===\n",
        "joblib.dump(rf_model, \"random_forest_model.pkl\")\n",
        "joblib.dump(scaler, \"rf_scaler.pkl\")\n",
        "joblib.dump(label_encoder, \"rf_label_encoder.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jb1PPP0l56V",
        "outputId": "1c4a3e00-8474-47ca-ea08-44df548d5553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Accuracy: 0.9946595460614153\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         air       0.80      1.00      0.89         4\n",
            "   hyperloop       0.99      1.00      1.00       555\n",
            "        rail       1.00      0.98      0.99       182\n",
            "        road       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.99       749\n",
            "   macro avg       0.95      1.00      0.97       749\n",
            "weighted avg       0.99      0.99      0.99       749\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rf_label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SVM**"
      ],
      "metadata": {
        "id": "GPeFS-Xbu6kT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "\n",
        "\n",
        "# === Step 3: Encode target classes ===\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # e.g., 'rail' â†’ 0\n",
        "\n",
        "# === Step 4: Train-test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# === Step 5: Normalize features ===\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# === Step 6: Train SVM classifier ===\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# === Step 7: Evaluation ===\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "print(\"âœ… Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# === Step 8: Save model and preprocessing ===\n",
        "joblib.dump(svm_model, \"svm_model.pkl\")\n",
        "joblib.dump(scaler, \"svm_scaler.pkl\")\n",
        "joblib.dump(label_encoder, \"svm_label_encoder.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVkOFRpZnXEu",
        "outputId": "bee22fdd-9933-4702-87a6-1962caf4f158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Accuracy: 0.9559412550066756\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         air       0.00      0.00      0.00         4\n",
            "   hyperloop       0.96      0.99      0.97       555\n",
            "        rail       0.95      0.86      0.90       182\n",
            "        road       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.96       749\n",
            "   macro avg       0.73      0.71      0.72       749\n",
            "weighted avg       0.95      0.96      0.95       749\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['svm_label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic **Regression**"
      ],
      "metadata": {
        "id": "TeKfgPQ7u1tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "\n",
        "# === Step 3: Encode target labels ===\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # e.g., 'rail' â†’ 0\n",
        "\n",
        "# === Step 4: Train-test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# === Step 5: Normalize features ===\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# === Step 6: Train logistic regression model ===\n",
        "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# === Step 7: Evaluation ===\n",
        "y_pred = log_model.predict(X_test_scaled)\n",
        "print(\"âœ… Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# === Step 8: Save model and tools ===\n",
        "joblib.dump(log_model, \"log_model.pkl\")\n",
        "joblib.dump(scaler, \"log_scaler.pkl\")\n",
        "joblib.dump(label_encoder, \"log_label_encoder.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suewlzctsWrd",
        "outputId": "f474e727-4315-4051-ea86-73bc91086e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Accuracy: 0.9305740987983978\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         air       0.00      0.00      0.00         4\n",
            "   hyperloop       0.92      1.00      0.96       555\n",
            "        rail       0.97      0.77      0.86       182\n",
            "        road       1.00      0.25      0.40         8\n",
            "\n",
            "    accuracy                           0.93       749\n",
            "   macro avg       0.72      0.50      0.55       749\n",
            "weighted avg       0.93      0.93      0.92       749\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['log_label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IyFruc1ruv7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "# === Step 3: Encode target labels ===\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# === Step 4: Train-test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# === Step 5: Normalize features ===\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# === Step 6: Train KNN classifier ===\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# === Step 7: Evaluation ===\n",
        "y_pred = knn_model.predict(X_test_scaled)\n",
        "print(\"âœ… KNN Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# === Step 8: Save model and tools ===\n",
        "joblib.dump(knn_model, \"knn_model.pkl\")\n",
        "joblib.dump(scaler, \"knn_scaler.pkl\")\n",
        "joblib.dump(label_encoder, \"knn_label_encoder.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4i7c_vSsy90",
        "outputId": "a9888ea0-cd90-4068-b015-b069909c73cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… KNN Accuracy: 0.9572763684913218\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         air       1.00      1.00      1.00         4\n",
            "   hyperloop       0.96      0.98      0.97       555\n",
            "        rail       0.93      0.89      0.91       182\n",
            "        road       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.96       749\n",
            "   macro avg       0.97      0.97      0.97       749\n",
            "weighted avg       0.96      0.96      0.96       749\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['knn_label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Ensemble learning**"
      ],
      "metadata": {
        "id": "FcAGhd_bvOs7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ðŸŽ¯ Define base models\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[('rf', rf_model), ('knn', knn_model), ('xgb', xgb_model)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "\n",
        "# Train\n",
        "ensemble_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = ensemble_model.predict(X_test_scaled)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"âœ… Ensemble Voting Accuracy:\", acc)\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x67R04_FtCeN",
        "outputId": "127a83be-bd62-4a4f-daa2-17cada0ca65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Ensemble Voting Accuracy: 0.9959946595460614\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         air       1.00      1.00      1.00         3\n",
            "   hyperloop       0.99      1.00      1.00       559\n",
            "        rail       1.00      0.98      0.99       182\n",
            "        road       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00       749\n",
            "   macro avg       1.00      1.00      1.00       749\n",
            "weighted avg       1.00      1.00      1.00       749\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [14:02:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ToEcIFw22Sh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}