{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhi-nand-shaji/Optimal_Transport_Mode_Selector/blob/main/SER_ML_(Final).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3oOAHKA4lJId"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from imblearn.pipeline import Pipeline as ImbPipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AINPb8JJOh9Q",
        "outputId": "fbd56265-95ab-4d28-94b3-beb46356c86c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hITu7mGr_idg",
        "outputId": "1e39e3e9-349a-46b8-fece-0b94ef7a0d07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kvCGBKBK_lrv"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE, ADASYN\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mfxFhgAXlQCv"
      },
      "outputs": [],
      "source": [
        "# --- Step 1: Load & Clean Data ---\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/ML Data/DataforML.csv\", skiprows=1)\n",
        "# --- Rename Columns ---\n",
        "df.columns = [\n",
        "    \"Perishable\", \"Commodity\", \"Category\", \"Source\", \"Destination\", \"Density\", \"Demand\",\n",
        "    \"Distance_Rail\", \"Distance_Road\", \"Distance_Air\", \"Distance_Hyperloop\",\n",
        "    \"Time_Rail\", \"Time_Road\", \"Time_Air\", \"Time_Hyperloop\",\n",
        "    \"Cost_Rail\", \"Cost_Road\", \"Cost_Air\", \"Cost_Hyperloop\",\n",
        "    \"Carbon_Rail\", \"Carbon_Road\", \"Carbon_Air\", \"Carbon_Hyperloop\",\n",
        "    \"Unused1\", \"Unused2\"\n",
        "]\n",
        "df = df.drop(columns=[\"Unused1\", \"Unused2\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HWXUDsYoliR0"
      },
      "outputs": [],
      "source": [
        "# Convert necessary columns to numeric\n",
        "cols_to_convert = [\n",
        "    \"Distance_Rail\", \"Distance_Road\", \"Distance_Air\", \"Distance_Hyperloop\",\n",
        "    \"Time_Rail\", \"Time_Road\", \"Time_Air\", \"Time_Hyperloop\",\n",
        "    \"Cost_Rail\", \"Cost_Road\", \"Cost_Air\", \"Cost_Hyperloop\",\n",
        "    \"Carbon_Rail\", \"Carbon_Road\", \"Carbon_Air\", \"Carbon_Hyperloop\",\n",
        "    \"Demand\", \"Density\", \"Perishable\"\n",
        "]\n",
        "\n",
        "for col in cols_to_convert:\n",
        "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "# Drop rows with any NaNs\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tLxQhC78lk-e"
      },
      "outputs": [],
      "source": [
        "# Normalize Cost, Time, Carbon\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler_minmax = MinMaxScaler()\n",
        "for metric in [\"Cost\", \"Time\", \"Carbon\"]:\n",
        "    for mode in [\"Rail\", \"Road\", \"Air\", \"Hyperloop\"]:\n",
        "        df[f\"{metric}_{mode}\"] = scaler_minmax.fit_transform(df[[f\"{metric}_{mode}\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP3pFPz2spk-",
        "outputId": "1d0fcfa4-748d-4f5f-c376-2298661803bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Perishable              Commodity        Category   Source Destination  \\\n",
            "0           1                   Milk            FMCG  Chennai   Bangalore   \n",
            "1           1        Packaged Snacks            FMCG  Chennai   Bangalore   \n",
            "2           1                   Meat            FMCG  Chennai   Bangalore   \n",
            "3           1               Seafoods            FMCG  Chennai   Bangalore   \n",
            "4           1                Pickles            FMCG  Chennai   Bangalore   \n",
            "5           1           Leafy Greens  fruits/veggies  Chennai   Bangalore   \n",
            "6           1              Mushrooms  fruits/veggies  Chennai   Bangalore   \n",
            "7           1             Cut Fruits  fruits/veggies  Chennai   Bangalore   \n",
            "8           1               Vaccines          pharma  Chennai   Bangalore   \n",
            "9           1  Rapid Diagnostic Kits          pharma  Chennai   Bangalore   \n",
            "\n",
            "   Density  Demand  Distance_Rail  Distance_Road  Distance_Air  ...  Time_Air  \\\n",
            "0     1030       9            347            326           284  ...  0.103448   \n",
            "1      250       7            347            326           284  ...  0.103448   \n",
            "2     1060       8            347            326           284  ...  0.103448   \n",
            "3     1080       8            347            326           284  ...  0.103448   \n",
            "4     1100       6            347            326           284  ...  0.103448   \n",
            "5      150       9            347            326           284  ...  0.103448   \n",
            "6      160       8            347            326           284  ...  0.103448   \n",
            "7      600       9            347            326           284  ...  0.103448   \n",
            "8     1000      10            347            326           284  ...  0.103448   \n",
            "9      450      10            347            326           284  ...  0.103448   \n",
            "\n",
            "   Time_Hyperloop  Cost_Rail  Cost_Road  Cost_Air  Cost_Hyperloop  \\\n",
            "0        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "1        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "2        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "3        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "4        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "5        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "6        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "7        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "8        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "9        0.056604   0.069382   0.088176       0.1        0.085569   \n",
            "\n",
            "   Carbon_Rail  Carbon_Road  Carbon_Air  Carbon_Hyperloop  \n",
            "0     0.068345     0.087941         0.1          0.057312  \n",
            "1     0.068345     0.087941         0.1          0.057312  \n",
            "2     0.068345     0.087941         0.1          0.057312  \n",
            "3     0.068345     0.087941         0.1          0.057312  \n",
            "4     0.068345     0.087941         0.1          0.057312  \n",
            "5     0.068345     0.087941         0.1          0.057312  \n",
            "6     0.068345     0.087941         0.1          0.057312  \n",
            "7     0.068345     0.087941         0.1          0.057312  \n",
            "8     0.068345     0.087941         0.1          0.057312  \n",
            "9     0.068345     0.087941         0.1          0.057312  \n",
            "\n",
            "[10 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "032fE7A8lnqa"
      },
      "outputs": [],
      "source": [
        "# Compute weighted scores for each mode\n",
        "def get_adjusted_weights(demand_0_to_10, perishable):\n",
        "    base_cost = 0.452\n",
        "    base_carbon = 0.267\n",
        "    base_time = 0.281\n",
        "    demand = min(max(demand_0_to_10 / 10.0, 0), 1)\n",
        "    perishability_factor = 0.1 if perishable else 0.0\n",
        "    demand_factor = demand * 0.2\n",
        "    w_time = base_time + perishability_factor + demand_factor\n",
        "    w_carbon = base_carbon + 0.5 * perishability_factor\n",
        "    w_cost = 1.0 - w_time - w_carbon\n",
        "    return w_cost, w_carbon, w_time\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    w_cost, w_carbon, w_time = get_adjusted_weights(row[\"Demand\"], row[\"Perishable\"])\n",
        "    for mode in [\"Rail\", \"Road\", \"Air\", \"Hyperloop\"]:\n",
        "        df.at[idx, f\"Score_{mode}\"] = (\n",
        "            w_cost * row[f\"Cost_{mode}\"] +\n",
        "            w_carbon * row[f\"Carbon_{mode}\"] +\n",
        "            w_time * row[f\"Time_{mode}\"]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Fd7dbjs-5_DC"
      },
      "outputs": [],
      "source": [
        "# Define best mode\n",
        "df[\"Best_Mode\"] = df[[\"Score_Rail\", \"Score_Road\", \"Score_Air\", \"Score_Hyperloop\"]].idxmin(axis=1)\n",
        "df[\"Best_Mode\"] = df[\"Best_Mode\"].map({\n",
        "    \"Score_Rail\": \"rail\",\n",
        "    \"Score_Road\": \"road\",\n",
        "    \"Score_Air\": \"air\",\n",
        "    \"Score_Hyperloop\": \"hyperloop\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-RuvBFc26G9M"
      },
      "outputs": [],
      "source": [
        "# Feature selection\n",
        "feature_cols = [\n",
        "    \"Cost_Rail\", \"Cost_Road\", \"Cost_Air\", \"Cost_Hyperloop\",\n",
        "    \"Time_Rail\", \"Time_Road\", \"Time_Air\", \"Time_Hyperloop\",\n",
        "    \"Carbon_Rail\", \"Carbon_Road\", \"Carbon_Air\", \"Carbon_Hyperloop\",\n",
        "    \"Demand\", \"Density\", \"Perishable\"\n",
        "]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df[\"Best_Mode\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "s5EmFV6mGzp2"
      },
      "outputs": [],
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6_1iQyqG4kh",
        "outputId": "9b0f705e-3409-4034-fdf1-5d98be02faa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "\n",
            "ðŸ“Š Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         air       0.89      1.00      0.94         8\n",
            "   hyperloop       1.00      1.00      1.00       677\n",
            "        rail       1.00      1.00      1.00       207\n",
            "        road       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00       900\n",
            "   macro avg       0.97      1.00      0.98       900\n",
            "weighted avg       1.00      1.00      1.00       900\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Define pipeline with SMOTE and MLPClassifier\n",
        "pipeline = ImbPipeline([\n",
        "    ('smote', SMOTE(random_state=42)),\n",
        "    ('clf', MLPClassifier(max_iter=1000, random_state=42))\n",
        "])\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'clf__hidden_layer_sizes': [(100, 50), (200, 100), (300, 200)],\n",
        "    'clf__alpha': [0.0001, 0.001],\n",
        "    'clf__activation': ['relu', 'tanh']\n",
        "}\n",
        "\n",
        "# Run Grid Search CV\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1_macro',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Predict and Evaluate\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(\"\\nðŸ“Š Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fLkD-qYDF85",
        "outputId": "6c21d8ed-f162-43c4-dec6-cea4c88ccea7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… Results saved as 'ml_predictions_with_originals.csv'\n"
          ]
        }
      ],
      "source": [
        "# Save predictions with original data\n",
        "X_original = scaler.inverse_transform(X_test)\n",
        "original_features_df = pd.DataFrame(X_original, columns=feature_cols)\n",
        "source_dest_df = df[[\"Source\", \"Destination\"]].loc[X.index].reset_index(drop=True)\n",
        "predicted_modes = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "final_df = pd.concat([\n",
        "    original_features_df.reset_index(drop=True),\n",
        "    source_dest_df,\n",
        "    pd.Series(predicted_modes, name=\"Predicted_Mode\")\n",
        "], axis=1)\n",
        "\n",
        "final_df.to_csv(\"ml_predictions_with_originals.csv\", index=False)\n",
        "print(\"\\nâœ… Results saved as 'ml_predictions_with_originals.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLSOBOHjZbtQ",
        "outputId": "8e2b152e-6f43-41d6-d548-901d767c6734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“‰ RMSE: 0.04714045207910317\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Ensure y_test and y_pred are 1D arrays of class indices\n",
        "# If y_test is still one-hot encoded, convert it back\n",
        "# If it's already label-encoded, you can use it directly\n",
        "\n",
        "# Compute RMSE\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(\"ðŸ“‰ RMSE:\", rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "L6fNwmXxYdvp"
      },
      "outputs": [],
      "source": [
        "cost_scaler = MinMaxScaler().fit(df[[\"Cost_Rail\", \"Cost_Road\", \"Cost_Air\", \"Cost_Hyperloop\"]])\n",
        "time_scaler = MinMaxScaler().fit(df[[\"Time_Rail\", \"Time_Road\", \"Time_Air\", \"Time_Hyperloop\"]])\n",
        "carbon_scaler = MinMaxScaler().fit(df[[\"Carbon_Rail\", \"Carbon_Road\", \"Carbon_Air\", \"Carbon_Hyperloop\"]])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMmob9-EYa6j",
        "outputId": "c77bdabc-3a45-42db-cb4e-3807d7b5088b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['carbon_scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import joblib\n",
        "joblib.dump(cost_scaler, \"cost_scaler.pkl\")\n",
        "joblib.dump(time_scaler, \"time_scaler.pkl\")\n",
        "joblib.dump(carbon_scaler, \"carbon_scaler.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "D4gsn7YjXKfB"
      },
      "outputs": [],
      "source": [
        "# Normalize Cost, Time, Carbon\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# ðŸ‘‡ Define these outside so we can reuse them later\n",
        "cost_scaler.pkl = MinMaxScaler()\n",
        "time_scaler.pkl = MinMaxScaler()\n",
        "carbon_scaler.pkl = MinMaxScaler()\n",
        "\n",
        "for metric, scaler in zip([\"Cost\", \"Time\", \"Carbon\"], [cost_scaler, time_scaler, carbon_scaler]):\n",
        "    cols = [f\"{metric}_{mode}\" for mode in [\"Rail\", \"Road\", \"Air\", \"Hyperloop\"]]\n",
        "    df[cols] = scaler.fit_transform(df[cols])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Lrn850-MApU3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "\n",
        "# ---- Step 1: Estimate raw cost, time, and carbon metrics ----\n",
        "def estimate_metrics_from_distance(distance_km):\n",
        "    return {\n",
        "        \"cost\": {\n",
        "            \"rail\": 0.00136 * distance_km,\n",
        "            \"road\": 0.0028 * distance_km,\n",
        "            \"air\": 0.025 * distance_km,\n",
        "            \"hyperloop\": 0.00415242 * distance_km,\n",
        "        },\n",
        "        \"time\": {\n",
        "            \"rail\": (distance_km / 60),\n",
        "            \"road\": (distance_km / 50),\n",
        "            \"air\": (distance_km / 850),\n",
        "            \"hyperloop\": (distance_km / 765)\n",
        "        },\n",
        "        \"carbon\": {\n",
        "            \"rail\": 0.00996 * distance_km,\n",
        "            \"road\": 0.062 * distance_km,\n",
        "            \"air\": 0.6 * distance_km,\n",
        "            \"hyperloop\": 0.006 * distance_km\n",
        "        }\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "aghE7hHqWQh6"
      },
      "outputs": [],
      "source": [
        "# ---- Step 2: Normalize metrics using fitted scalers ----\n",
        "def normalize_metrics(metrics, cost_scaler, time_scaler, carbon_scaler):\n",
        "    cost_df = pd.DataFrame([{\n",
        "        \"Cost_Rail\": metrics[\"cost\"][\"rail\"],\n",
        "        \"Cost_Road\": metrics[\"cost\"][\"road\"],\n",
        "        \"Cost_Air\": metrics[\"cost\"][\"air\"],\n",
        "        \"Cost_Hyperloop\": metrics[\"cost\"][\"hyperloop\"]\n",
        "    }])\n",
        "    time_df = pd.DataFrame([{\n",
        "        \"Time_Rail\": metrics[\"time\"][\"rail\"],\n",
        "        \"Time_Road\": metrics[\"time\"][\"road\"],\n",
        "        \"Time_Air\": metrics[\"time\"][\"air\"],\n",
        "        \"Time_Hyperloop\": metrics[\"time\"][\"hyperloop\"]\n",
        "    }])\n",
        "    carbon_df = pd.DataFrame([{\n",
        "        \"Carbon_Rail\": metrics[\"carbon\"][\"rail\"],\n",
        "        \"Carbon_Road\": metrics[\"carbon\"][\"road\"],\n",
        "        \"Carbon_Air\": metrics[\"carbon\"][\"air\"],\n",
        "        \"Carbon_Hyperloop\": metrics[\"carbon\"][\"hyperloop\"]\n",
        "    }])\n",
        "\n",
        "    cost_scaled = cost_scaler.transform(cost_df)[0]\n",
        "    time_scaled = time_scaler.transform(time_df)[0]\n",
        "    carbon_scaled = carbon_scaler.transform(carbon_df)[0]\n",
        "\n",
        "    normalized = {\n",
        "        \"cost\": dict(zip([\"rail\", \"road\", \"air\", \"hyperloop\"], cost_scaled)),\n",
        "        \"time\": dict(zip([\"rail\", \"road\", \"air\", \"hyperloop\"], time_scaled)),\n",
        "        \"carbon\": dict(zip([\"rail\", \"road\", \"air\", \"hyperloop\"], carbon_scaled))\n",
        "    }\n",
        "\n",
        "    return normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "r5gxr-VjWSI_"
      },
      "outputs": [],
      "source": [
        "# ---- Step 3: Calculate weighted scores and return best mode ----\n",
        "def weighted_score_mode_selection(normalized_metrics, demand, perishable):\n",
        "    base_cost = 0.452\n",
        "    base_carbon = 0.267\n",
        "    base_time = 0.281\n",
        "    perishability_factor = 0.1 if perishable else -0.1\n",
        "    demand_factor = min(max(demand / 10.0, 0), 1) * 0.2\n",
        "\n",
        "    w_time = base_time + perishability_factor + demand_factor\n",
        "    w_carbon = base_carbon + 0.1 * perishability_factor\n",
        "    w_cost = 1.0 - w_time - w_carbon\n",
        "\n",
        "    scores = {}\n",
        "    for mode in [\"rail\", \"road\", \"air\", \"hyperloop\"]:\n",
        "        score = (\n",
        "            w_cost * normalized_metrics[\"cost\"][mode] +\n",
        "            w_time * normalized_metrics[\"time\"][mode] +\n",
        "            w_carbon * normalized_metrics[\"carbon\"][mode]\n",
        "        )\n",
        "        scores[mode] = score\n",
        "\n",
        "    best_mode = min(scores, key=scores.get)\n",
        "    return best_mode, scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zth1hiHuWWyS"
      },
      "outputs": [],
      "source": [
        "# ---- Step 4: Wrapper to run rule-based prediction ----\n",
        "def rule_based_predict_mode(distance_km, demand, density, perishable, cost_scaler, time_scaler, carbon_scaler):\n",
        "    raw_metrics = estimate_metrics_from_distance(distance_km)\n",
        "    normalized_metrics = normalize_metrics(raw_metrics, cost_scaler, time_scaler, carbon_scaler)\n",
        "    best_mode, score_dict = weighted_score_mode_selection(normalized_metrics, demand, perishable)\n",
        "    return best_mode, score_dict, raw_metrics\n",
        "\n",
        "# ---- Load your previously trained scalers ----\n",
        "cost_scaler = joblib.load(\"cost_scaler.pkl\")\n",
        "time_scaler = joblib.load(\"time_scaler.pkl\")\n",
        "carbon_scaler = joblib.load(\"carbon_scaler.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8U-5I4FXc4d",
        "outputId": "a2600c8d-4c9b-4a65-d755-7f7a2a2a3072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸšš Rule-Based Best Mode: hyperloop\n",
            "ðŸ“Š Normalized Scores: {'rail': np.float64(9.09590666666667), 'road': np.float64(24.223599999999998), 'air': np.float64(164.17470588235295), 'hyperloop': np.float64(3.6001198648366017)}\n",
            "ðŸ§¾ Raw Metrics (Unnormalized): {'cost': {'rail': 1.36, 'road': 2.8, 'air': 25.0, 'hyperloop': 4.15242}, 'time': {'rail': 16.666666666666668, 'road': 20.0, 'air': 1.1764705882352942, 'hyperloop': 1.3071895424836601}, 'carbon': {'rail': 9.96, 'road': 62.0, 'air': 600.0, 'hyperloop': 6.0}}\n"
          ]
        }
      ],
      "source": [
        "# ---- Predict best mode for Chennai â†’ Bangalore ----\n",
        "mode, scores, raw = rule_based_predict_mode(\n",
        "    distance_km=1000,\n",
        "    demand=9,\n",
        "    density=600,  # Not used but kept for API consistency\n",
        "    perishable=False,\n",
        "    cost_scaler=cost_scaler,\n",
        "    time_scaler=time_scaler,\n",
        "    carbon_scaler=carbon_scaler\n",
        ")\n",
        "\n",
        "# ---- Display results ----\n",
        "print(\"ðŸšš Rule-Based Best Mode:\", mode)\n",
        "print(\"ðŸ“Š Normalized Scores:\", scores)\n",
        "print(\"ðŸ§¾ Raw Metrics (Unnormalized):\", raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwuZ5iCUlv_t"
      },
      "source": [
        "# LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEdowTx7Yf5Y",
        "outputId": "77415bcc-172d-4dc2-ac98-2c2b8ceac54c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000226 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1239\n",
            "[LightGBM] [Info] Number of data points in the train set: 2098, number of used features: 15\n",
            "[LightGBM] [Info] Start training from score -4.815526\n",
            "[LightGBM] [Info] Start training from score -0.284193\n",
            "[LightGBM] [Info] Start training from score -1.466655\n",
            "[LightGBM] [Info] Start training from score -4.758368\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         air       0.89      1.00      0.94         8\n",
            "   hyperloop       1.00      1.00      1.00       677\n",
            "        rail       1.00      1.00      1.00       207\n",
            "        road       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00       900\n",
            "   macro avg       0.97      1.00      0.98       900\n",
            "weighted avg       1.00      1.00      1.00       900\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Split the data correctly (shuffled and stratified)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Scale only on train\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 3. Train LightGBM or XGBoost cleanly\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "model = LGBMClassifier(random_state=42)\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# 4. Evaluate\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEJ7uvYFl2-c"
      },
      "source": [
        "# **XGBoost**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVBnF2Ukk--l",
        "outputId": "325413b5-9264-41a0-a87c-c77ccdd990fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:57:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“Š Classification Report for XGBoost:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         air       0.89      1.00      0.94         8\n",
            "   hyperloop       1.00      1.00      1.00       677\n",
            "        rail       0.99      1.00      1.00       207\n",
            "        road       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00       900\n",
            "   macro avg       0.97      1.00      0.98       900\n",
            "weighted avg       1.00      1.00      1.00       900\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # Converts ['rail', 'road', ...] â†’ [0, 1, 2, 3]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# ----- Step 2: Scale Features -----\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Save the scaler for future use\n",
        "joblib.dump(scaler, \"xgb_scaler.pkl\")\n",
        "\n",
        "# ----- Step 3: Train XGBoost Model -----\n",
        "xgb_model = XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=len(np.unique(y)),  # number of classes\n",
        "    max_depth=4,\n",
        "    learning_rate=0.1,\n",
        "    n_estimators=100,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(xgb_model, \"xgb_model.pkl\")\n",
        "\n",
        "# ----- Step 4: Evaluate -----\n",
        "y_pred = xgb_model.predict(X_test_scaled)\n",
        "\n",
        "print(\"ðŸ“Š Classification Report for XGBoost:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdIovv4VnNFl"
      },
      "source": [
        "# **RandomForest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jb1PPP0l56V",
        "outputId": "9b4aca6e-6840-461b-8503-765f604fb160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸŽ¯ Accuracy: 0.9988888888888889\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         air       0.89      1.00      0.94         8\n",
            "   hyperloop       1.00      1.00      1.00       677\n",
            "        rail       1.00      1.00      1.00       207\n",
            "        road       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00       900\n",
            "   macro avg       0.97      1.00      0.99       900\n",
            "weighted avg       1.00      1.00      1.00       900\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['rf_label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "\n",
        "\n",
        "# === Step 3: Label Encode target ===\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # ['rail', 'road', ...] â†’ [0, 1, 2, 3]\n",
        "\n",
        "# === Step 4: Train-test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# === Step 5: Scale features ===\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# === Step 6: Train Random Forest model ===\n",
        "rf_model = RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=10,\n",
        "    random_state=42\n",
        ")\n",
        "rf_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# === Step 7: Evaluate model ===\n",
        "y_pred = rf_model.predict(X_test_scaled)\n",
        "print(\"ðŸŽ¯ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# === Step 8: Save model and encoders ===\n",
        "joblib.dump(rf_model, \"random_forest_model.pkl\")\n",
        "joblib.dump(scaler, \"rf_scaler.pkl\")\n",
        "joblib.dump(label_encoder, \"rf_label_encoder.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPeFS-Xbu6kT"
      },
      "source": [
        "# **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVkOFRpZnXEu",
        "outputId": "9730df19-fc2e-4a8e-aa88-75d1fa203553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Accuracy: 0.9444444444444444\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         air       0.00      0.00      0.00         8\n",
            "   hyperloop       0.94      1.00      0.97       677\n",
            "        rail       0.95      0.80      0.87       207\n",
            "        road       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.94       900\n",
            "   macro avg       0.72      0.70      0.71       900\n",
            "weighted avg       0.94      0.94      0.94       900\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['svm_label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "\n",
        "\n",
        "# === Step 3: Encode target classes ===\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # e.g., 'rail' â†’ 0\n",
        "\n",
        "# === Step 4: Train-test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# === Step 5: Normalize features ===\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# === Step 6: Train SVM classifier ===\n",
        "svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', probability=True, random_state=42)\n",
        "svm_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# === Step 7: Evaluation ===\n",
        "y_pred = svm_model.predict(X_test_scaled)\n",
        "print(\"âœ… Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# === Step 8: Save model and preprocessing ===\n",
        "joblib.dump(svm_model, \"svm_model.pkl\")\n",
        "joblib.dump(scaler, \"svm_scaler.pkl\")\n",
        "joblib.dump(label_encoder, \"svm_label_encoder.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeKfgPQ7u1tv"
      },
      "source": [
        "# Logistic **Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suewlzctsWrd",
        "outputId": "adacd79e-1367-4821-d7ea-314ca127b0df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Accuracy: 0.9444444444444444\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         air       0.00      0.00      0.00         8\n",
            "   hyperloop       0.94      1.00      0.97       677\n",
            "        rail       0.96      0.84      0.89       207\n",
            "        road       0.00      0.00      0.00         8\n",
            "\n",
            "    accuracy                           0.94       900\n",
            "   macro avg       0.48      0.46      0.47       900\n",
            "weighted avg       0.93      0.94      0.93       900\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['log_label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "\n",
        "# === Step 3: Encode target labels ===\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)  # e.g., 'rail' â†’ 0\n",
        "\n",
        "# === Step 4: Train-test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# === Step 5: Normalize features ===\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# === Step 6: Train logistic regression model ===\n",
        "log_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "log_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# === Step 7: Evaluation ===\n",
        "y_pred = log_model.predict(X_test_scaled)\n",
        "print(\"âœ… Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# === Step 8: Save model and tools ===\n",
        "joblib.dump(log_model, \"log_model.pkl\")\n",
        "joblib.dump(scaler, \"log_scaler.pkl\")\n",
        "joblib.dump(label_encoder, \"log_label_encoder.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyFruc1ruv7Y"
      },
      "source": [
        "# KNN\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4i7c_vSsy90",
        "outputId": "54cb148a-176f-4175-cf36-6d218d158a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… KNN Accuracy: 0.9522222222222222\n",
            "ðŸ“Š Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         air       1.00      1.00      1.00         8\n",
            "   hyperloop       0.96      0.98      0.97       677\n",
            "        rail       0.93      0.86      0.89       207\n",
            "        road       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           0.95       900\n",
            "   macro avg       0.97      0.96      0.97       900\n",
            "weighted avg       0.95      0.95      0.95       900\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['knn_label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "# === Step 3: Encode target labels ===\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# === Step 4: Train-test split ===\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "# === Step 5: Normalize features ===\n",
        "scaler = MinMaxScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# === Step 6: Train KNN classifier ===\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# === Step 7: Evaluation ===\n",
        "y_pred = knn_model.predict(X_test_scaled)\n",
        "print(\"âœ… KNN Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"ðŸ“Š Classification Report:\\n\", classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "# === Step 8: Save model and tools ===\n",
        "joblib.dump(knn_model, \"knn_model.pkl\")\n",
        "joblib.dump(scaler, \"knn_scaler.pkl\")\n",
        "joblib.dump(label_encoder, \"knn_label_encoder.pkl\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcAGhd_bvOs7"
      },
      "source": [
        "# **Ensemble learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x67R04_FtCeN",
        "outputId": "487ab549-877e-4016-ca76-387a0a371308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [02:59:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Ensemble Voting Accuracy: 0.9977777777777778\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         air       1.00      1.00      1.00         6\n",
            "   hyperloop       1.00      1.00      1.00       696\n",
            "        rail       0.99      0.99      0.99       192\n",
            "        road       1.00      1.00      1.00         6\n",
            "\n",
            "    accuracy                           1.00       900\n",
            "   macro avg       1.00      1.00      1.00       900\n",
            "weighted avg       1.00      1.00      1.00       900\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n",
        "\n",
        "# Scale\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ðŸŽ¯ Define base models\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
        "\n",
        "ensemble_model = VotingClassifier(\n",
        "    estimators=[('rf', rf_model), ('knn', knn_model), ('xgb', xgb_model)],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "\n",
        "# Train\n",
        "ensemble_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = ensemble_model.predict(X_test_scaled)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(\"âœ… Ensemble Voting Accuracy:\", acc)\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nwgr7uUD5ubb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}